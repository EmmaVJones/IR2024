---
title: "Organize Station Metadata DRAFT"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(readxl)
library(sf)
library(pins)
library(config)
library(lubridate)

# Connect to server
conn <- config::get("connectionSettings") # get configuration settings

board_register_rsconnect(key = conn$CONNECT_API_KEY,  #Sys.getenv("CONNECT_API_KEY"),
                         server = conn$CONNECT_SERVER)#Sys.getenv("CONNECT_SERVER"))

```

## Overview

This project picks up after regional assessment staff attribute WQS and AU information to each station identified for inclusion in a given assessment cycle. 

This script combines the WQS and AU information archived by those applications (from the R Connect server) and attaches that information to all data associated with an assessment window.

This script combines draft data, as opposed to final data. Future iterations use final data to  for final application testing upon data release. This version is meant to assist application rebuilding processes prior to final data release. 


## Data Organization

In order to link all data in the IR window to the appropriate station information, we need to bring in a few preliminary datasets.

* Conventionals (final)
* Last cycle AU information (still draft)
* Station Attributes (from 1.preprocessingData steps)
    + WQS information
    + AU information (specifically for stations that did not exist in last cycle)
* WQA CEDS Station table template (bulk data upload template)
    + New for 2022IR cycle, DEQ is moving from ADB to a more ATTAINS-like system comprised of a module in CEDS known as CEDS WQA. The development team has released a template for the 'bulk data upload' component where assessors may upload station information (manually or automatically assessed) to expedite the population of the CEDS module. We need to use this new data model as a starting point as it contains information for AU attribution, critical to WQA CEDS and automated assessment tools.
* PCB Data from Mark


The following sections will detail bringing in these necessary data sources and organizing them in a format the automated scripts can digest.

### Conventionals 

This dataset is built using the ...\IR2024\1.preprocessData\HowToPullDraftConventionalsDataset.Rmd that combines final (March release) IR2022 conventionals data with the conventionals data pull taken from the monthly assessment analysis pinned on the R server (data in CEDS/ODS as of August 15, 2022). That dataset was then filtered to the current assessment window, 2017-2022. 

This data is pulled from the R server and acts as "The" conventionals dataset for all IR2024 application testing/development.


```{r}
conventionals <- pin_get('ejones/conventionals2024draft', board = 'rsconnect')
```

#### Station Hit list

These are the stations that assessors have asked to never see again in an assessment. They make it through the conventionals query but should not be assessed. 

Remove the offenders marked by assessors during metadata attribution process that need to be cut from the conventionals pull and not assessed. 

```{r station hit list}
hitList <- read_csv('data/stationHitList.csv')

conventionals <- filter(conventionals, ! FDT_STA_ID %in% toupper(hitList$`StationID to Remove`))
rm(hitList)
```

#### Citmon/NonAgency Data

Need to add in after talking to Reid.

#### Conventionals Distinct

And now let's make a dataset of all the unique stations that we need to organize.

```{r conventionals_distinct}
# conventionals_distinct <- conventionals %>%
#   distinct(FDT_STA_ID, .keep_all = T) %>%
#   # remove any data to avoid confusion
#   dplyr::select(FDT_STA_ID:FDT_COMMENT, Latitude:Data_Source) %>%
#   filter(!is.na(FDT_STA_ID))
conventionals_distinct <- pin_get('ejones/conventionals2024_distinctdraft', board = 'rsconnect') %>% 
  filter(!is.na(Latitude) | !is.na(Longitude))


# and make a spatial version
conventionals_sf <- conventionals_distinct %>%
  st_as_sf(coords = c("Longitude", "Latitude"), 
               remove = F, # don't remove these lat/lon cols from df
               crs = 4326) # add projection, needs to be geographic for now bc entering lat/lng

```



#### Stations Bulk Upload Template 

The biggest changes from the old stations table format to this new template is the addition of the 10 ID305B and station type columns as well as the lacustrine designation. 

```{r bulk upload template}
stationsTemplate <- read_excel('data/WQA_CEDS_templates/WQA_Bulk_Station_Upload_Final.xlsx',#'WQA_CEDS_templates/WQA_Bulk_Station_Upload (3).xlsx', 
                               sheet = 'Stations', col_types = "text")[0,] # just want structure and not the draft data, force everything to character for now
```


#### Last cycle AU information (draft)

Let's start by populating this template with draft 2022 stations table information. This will be the first time we pull this information from ODS instead of being supplied data from Cleo.

Connect to ODS prod.

```{r}
library(pool)
library(dbplyr)
### Production Environment
pool <- dbPool(
  drv = odbc::odbc(),
  Driver = "ODBC Driver 11 for SQL Server", #"SQL Server Native Client 11.0", 
  Server= "DEQ-SQLODS-PROD,50000",
  dbname = "ODS",
  trusted_connection = "yes"
)
```

Find all stations from the last IR cycle that should be carried forward for review this cycle, either impaired last time or with the comment field containing "carr%" string (e.g. carry over, carried over, etc.). Start by querying stations in IR2022 and join in their AU information and station parameters. The key to these joins is the 'WXA_STATION_DETAIL_ID'/'Station Detail Id' field.

```{r}
# data prep
stations <- pool %>% tbl(in_schema('wqa', "Wqa_Station_Details_View")) %>%
  filter(WSD_CYCLE == 2022) %>% 
  as_tibble() %>% 
  distinct(WXA_STATION_DETAIL_ID, .keep_all = T) %>%  # distinct on this variable for AU join or duplicated rows for stations
  filter(WSD_STATION_ID != '4AGSE013.78') # problem site OIS needs to deal with

# WQA geospatial data only seems to have citmon/non agency station locations. All other stations (DEQ) need to be queried from the WQM side of ODS
stationsGeospatial_wqa <- pool %>% tbl(in_schema('wqa', 'Wqa_Stations_Geospatial_Data_View')) %>%
  filter(Station_Id %in% !! stations$STA_NAME) %>% #stations$WSD_STATION_ID) %>%
  as_tibble() %>% 
  dplyr::select(Station_Id, Latitude, Longitude) 

# WQM geospatial data for DEQ stations
stationsGeospatial_wqm <- pool %>% tbl(in_schema('wqm', 'WQM_Sta_GIS_View')) %>% 
  filter(Station_Id %in% !! stations$WSD_STATION_ID) %>% 
  as_tibble() %>% 
  dplyr::select(Station_Id, Latitude, Longitude) 

# combine geospatial data into one object for easier joining
stationsGeospatial <- bind_rows(stationsGeospatial_wqa, stationsGeospatial_wqm) %>% 
  distinct(Station_Id, .keep_all = T) %>% 
  mutate(Station_Id = case_when(Station_Id == 'Griggs Pond' ~ toupper(Station_Id),
                                Station_Id == 'Sims Metal 003' ~ 'SIMS METAL 003',
                                TRUE ~ as.character(Station_Id))) # Joining problems later if we don't capitalize the names Griggs Pond and Simms Metal 003 as they are elsewhere in ODS

AU <- pool %>% tbl(in_schema('wqa', '[WQA 305b]')) %>% # **note** need to put views with spaces in name in brackets for SQL to work
  filter(`Station Detail Id` %in% !! stations$WXA_STATION_DETAIL_ID) %>% 
  as_tibble()

stationDetails <- pool %>% tbl(in_schema('wqa', '[WQA Station Parameters Pivot]')) %>% # **note** need to put views with spaces in name in brackets for SQL to work
  filter(`Station Detail Id` %in% !! stations$WXA_STATION_DETAIL_ID) %>% 
  as_tibble()

stationType <- pool %>% tbl(in_schema('wqa', '[WQA Station Detail Types]')) %>% # **note** need to put views with spaces in name in brackets for SQL to work
  filter(`Station Detail Id` %in% !! stations$WXA_STATION_DETAIL_ID) %>% 
  as_tibble()

stationsAU <- left_join(stations, AU, by = c('WXA_STATION_DETAIL_ID' = 'Station Detail Id')) %>% 
  left_join(stationType, by =  c('WXA_STATION_DETAIL_ID' = 'Station Detail Id')) %>% 
  left_join(stationsGeospatial, by = c('STA_NAME' = 'Station_Id')) %>% # Make sure you join on STA_NAME and not WSD_STATION_ID here!!!
  left_join(stationDetails,  by = c('WXA_STATION_DETAIL_ID' = 'Station Detail Id')) 

# actual analysis
impairedStations <- stationsAU %>% 
  filter_at(.vars = vars(contains("Status Code")),
            .vars_predicate = any_vars(str_detect(., 'IM')))
carryoverStations <- stationsAU %>% 
  filter(str_detect(WSD_COMMENTS, 'carr'))

# combine and remove duplicates
stationsFromLastCycle <- bind_rows(impairedStations, carryoverStations) %>% 
  distinct(WXA_STATION_DETAIL_ID, .keep_all = T)

# clean up workspace
rm(list = c('stations','stationsAU', 'stationDetails', 'impairedStations', 'carryoverStations', 
            'AU', 'stationType', 'stationsGeospatial_wqa', 'stationsGeospatial_wqm'))
```

Clean up this data to match the bulk upload data template. We will also strip out the data to not confuse anyone from cycle to cycle.

```{r match bulk upload template}
stationsTable2024begin <- stationsFromLastCycle %>% 
  dplyr::select(STATION_ID = STA_NAME,  #### OR COULD USE WSD_STATION_ID
                ID305B_1 = `ID305B 1`,
                ID305B_2 = `ID305B 2`,
                ID305B_3 = `ID305B 3`,
                ID305B_4 = `ID305B 4`,
                ID305B_5 = `ID305B 5`,
                ID305B_6 = `ID305B 6`,
                ID305B_7 = `ID305B 7`,
                ID305B_8 = `ID305B 8`,
                ID305B_9 = `ID305B 9`,
                ID305B_10 = `ID305B 10`,
                WATER_TYPE = WWT_WATER_TYPE_DESC,
                SALINITY = WSC_DESCRIPTION,
                LACUSTRINE = WSD_LAC_ZONE_YN,
                REGION = STA_REGION,
                TYPE_1 = `Station Type 1`,
                TYPE_2 = `Station Type 2`,
                TYPE_3 = `Station Type 3`,
                TYPE_4 = `Station Type 4`,
                TYPE_5 = `Station Type 5`,
                TYPE_6 = `Station Type 6`,
                TYPE_7 = `Station Type 7`,
                TYPE_8 = `Station Type 8`,
                TYPE_9 = `Station Type 9`,
                TYPE_10 = `Station Type 10`,
                LATITUDE = Latitude,
                LONGITUDE = Longitude,
                WATERSHED = STA_WATERSHED,
                VAHU6 = STA_VA_HU6) %>% 
  mutate(REGION = case_when(REGION == 'NVRO' ~ 'NRO',
                            REGION == 'WCRO' ~ 'BRRO',
                            TRUE~ as.character(REGION))) %>% 
  dplyr::select(any_of(names(stationsTemplate)))

stationsTable2024begin <- bind_rows(stationsTemplate %>% 
                                      mutate(LATITUDE = as.numeric(LATITUDE),
                                             LONGITUDE = as.numeric(LONGITUDE)), 
                                    stationsTable2024begin) # add back in missing columns

```

QA check for any missing geospatial data. Goose creek site that was moved still has wqa records that need to be fixed bc all other records of this site are gone from CEDS WQM.

```{r}
missingGeospatial <- filter(stationsTable2024begin, is.na(LATITUDE) | is.na(LONGITUDE))

# #Goose creek issue:
# goose <- pool %>% tbl(in_schema('wqa', "Wqa_Station_Details_View")) %>%
#      filter(WSD_STATION_ID == '4AGSE013.78' |
#                 WSD_STATION_ID == '4AGSE013.45') %>% 
#      as_tibble() %>% 
#      arrange(WSD_CYCLE, WSD_STATION_ID)

# clean up workspace
rm(list = c('stationsFromLastCycle','missingGeospatial'))
```


Now we need to get the same metadata for all the stations from the conventionals (and citmon) dataset this cycle. We can make our lives easier by only doing this work for new stations from the conventionals dataset (i.e. dropping all stations from our "to do list" that already have this information from our last step).

```{r}
stationsToDo <- filter(conventionals_distinct, ! FDT_STA_ID %in% stationsTable2024begin$STATION_ID)

# use the same method from above with a new station list
stations <- pool %>% tbl(in_schema('wqa', "Wqa_Station_Details_View")) %>%
  filter(WSD_STATION_ID %in% !! stationsToDo$FDT_STA_ID) %>% # pull all data from stations identified above
  as_tibble() %>% # get that data local before doing more complicated things than SQL wants to handle
  # keep only the most recent record for each station by grouping and then filtering
  group_by(WSD_STATION_ID) %>% 
  filter(WSD_CYCLE == max(WSD_CYCLE )) %>% 
  distinct(WXA_STATION_DETAIL_ID, .keep_all = T) %>%  # still need only 1 record per site
  ungroup() # ungroup so the WSD_STATION_ID column doesn't come along for the ride to future steps where not necessary
  
# WQA geospatial data only seems to have citmon/non agency station locations. All other stations (DEQ) need to be queried from the WQM side of ODS
stationsGeospatial_wqa <- pool %>% tbl(in_schema('wqa', 'Wqa_Stations_Geospatial_Data_View')) %>%
  filter(Station_Id %in% !! stations$STA_NAME) %>% #stations$WSD_STATION_ID) %>%
  as_tibble() %>% 
  dplyr::select(Station_Id, Latitude, Longitude) 

# WQM geospatial data for DEQ stations
stationsGeospatial_wqm <- pool %>% tbl(in_schema('wqm', 'WQM_Sta_GIS_View')) %>% 
  filter(Station_Id %in% !! stations$WSD_STATION_ID) %>% 
  as_tibble() %>% 
  dplyr::select(Station_Id, Latitude, Longitude) 

# combine geospatial data into one object for easier joining
stationsGeospatial <- bind_rows(stationsGeospatial_wqa, stationsGeospatial_wqm) %>% 
  distinct(Station_Id, .keep_all = T)

AU <- pool %>% tbl(in_schema('wqa', '[WQA 305b]')) %>% # **note** need to put views with spaces in name in brackets for SQL to work
  filter(`Station Detail Id` %in% !! stations$WXA_STATION_DETAIL_ID) %>% 
  as_tibble()

stationDetails <- pool %>% tbl(in_schema('wqa', '[WQA Station Parameters Pivot]')) %>% # **note** need to put views with spaces in name in brackets for SQL to work
  filter(`Station Detail Id` %in% !! stations$WXA_STATION_DETAIL_ID) %>% 
  as_tibble()

stationType <- pool %>% tbl(in_schema('wqa', '[WQA Station Detail Types]')) %>% # **note** need to put views with spaces in name in brackets for SQL to work
  filter(`Station Detail Id` %in% !! stations$WXA_STATION_DETAIL_ID) %>% 
  as_tibble()

stationsAU <- left_join(stations, AU, by = c('WXA_STATION_DETAIL_ID' = 'Station Detail Id')) %>% 
  left_join(stationType, by =  c('WXA_STATION_DETAIL_ID' = 'Station Detail Id')) %>% 
  left_join(stationsGeospatial, by = c('STA_NAME' = 'Station_Id')) %>% # Make sure you join on STA_NAME and not WSD_STATION_ID here!!!
  left_join(stationDetails,  by = c('WXA_STATION_DETAIL_ID' = 'Station Detail Id')) %>% 
  # reorganize to fit the data template
  dplyr::select(STATION_ID = STA_NAME,  #### OR COULD USE WSD_STATION_ID
                ID305B_1 = `ID305B 1`,
                ID305B_2 = `ID305B 2`,
                ID305B_3 = `ID305B 3`,
                ID305B_4 = `ID305B 4`,
                ID305B_5 = `ID305B 5`,
                ID305B_6 = `ID305B 6`,
                ID305B_7 = `ID305B 7`,
                ID305B_8 = `ID305B 8`,
                ID305B_9 = `ID305B 9`,
                ID305B_10 = `ID305B 10`,
                WATER_TYPE = WWT_WATER_TYPE_DESC,
                SALINITY = WSC_DESCRIPTION,
                LACUSTRINE = WSD_LAC_ZONE_YN,
                REGION = STA_REGION,
                TYPE_1 = `Station Type 1`,
                TYPE_2 = `Station Type 2`,
                TYPE_3 = `Station Type 3`,
                TYPE_4 = `Station Type 4`,
                TYPE_5 = `Station Type 5`,
                TYPE_6 = `Station Type 6`,
                TYPE_7 = `Station Type 7`,
                TYPE_8 = `Station Type 8`,
                TYPE_9 = `Station Type 9`,
                TYPE_10 = `Station Type 10`,
                LATITUDE = Latitude,
                LONGITUDE = Longitude,
                WATERSHED = STA_WATERSHED,
                VAHU6 = STA_VA_HU6) %>% 
  mutate(REGION = case_when(REGION == 'NVRO' ~ 'NRO',
                            REGION == 'WCRO' ~ 'BRRO',
                            TRUE~ as.character(REGION))) %>% 
  dplyr::select(any_of(names(stationsTemplate)))

# Smash in with the rest of the sites already organized
stationsTable2024begin <- bind_rows(stationsTable2024begin,
                                    stationsAU) 

# clean up workspace
rm(list = c('stations', 'stationDetails', 'stationsAU',
            'AU', 'stationType', 'stationsGeospatial_wqa', 'stationsGeospatial_wqm'))

```

What stations do we have left? These are stations that are in the conventionals dataset but don't have any historical records in CEDS WQA. We will reorganize them into the tempate format we need and add AU information from the pinned data on the R server.

```{r}
stationsToDo <- filter(conventionals_distinct, ! FDT_STA_ID %in% stationsTable2024begin$STATION_ID) %>% 
  # glean what we can to populate the data template
  dplyr::select(STATION_ID = FDT_STA_ID,
                WATER_TYPE = STA_LV1_CODE,
                TYPE_1 = STA_LV2_CODE,
                LATITUDE = Latitude,
                LONGITUDE = Longitude) %>% 
  mutate(# throw in a flag for swamp but still need to force it to a waterbody type the assessment tools understand
         TYPE_1 =  case_when(WATER_TYPE == 'SWAMP' ~ paste(TYPE_1, 'SWAMP', sep = ': '),
                             TRUE~ as.character(TYPE_1)),
         WATER_TYPE = ifelse(WATER_TYPE == 'SWAMP', NA, WATER_TYPE)) %>% 
  dplyr::select(any_of(names(stationsTemplate))) %>% 
  # Spatially join info we don't trust from CEDS WQM, first turn this into a spatial object
  st_as_sf(coords = c("LONGITUDE", "LATITUDE"), 
               remove = F, # don't remove these lat/lon cols from df
               crs = 4326) # add projection, needs to be geographic for now bc entering lat/lng

# get pinned AU data from the R server
AUlookup <- pin_get('ejones/AUlookup', board = 'rsconnect') %>% 
  filter(CYCLE == 2024) # only get sites attributed by assessors for this cycle

# get spatial data from the R server
vahu6 <- st_as_sf(pin_get("ejones/AssessmentRegions_VA84_basins", board = "rsconnect"))
dcr11 <- st_as_sf(pin_get("ejones/dcr11", board = "rsconnect"))

# Spatially join info we don't trust from CEDS WQM
stationsLeft <- st_join(stationsToDo, vahu6) %>% 
  dplyr::select(STATION_ID:LONGITUDE, VAHU6, REGION = ASSESS_REG) %>% 
  st_join(dcr11) %>% 
  dplyr::select(STATION_ID:REGION, WATERSHED = ANCODE) %>% 
  st_drop_geometry() %>% # turn back into tibble
  left_join(dplyr::select(AUlookup, FDT_STA_ID, ID305B_1 ), by = c('STATION_ID' = 'FDT_STA_ID'))

# smash into template
stationsTable2024begin <- bind_rows(stationsTable2024begin,
                                     stationsLeft)

# clean up workspace
rm(list = c('stationsLeft', 'stationsToDo', 'stationsTemplate',
            'stationsGeospatial', 'dcr11', 'vahu6', 'AUlookup'))
```

Now let's pin this to the R server so others can use the data.

```{r}
pin(stationsTable2024begin, description = 'DRAFT stationsTable2024begin for IR2024 development', board = 'rsconnect')
```





Now add in new 2024IR data from conventionals (and eventually citmon)


```{r}
station <- '4AROA167.34'

test <- pool %>% tbl(in_schema('wqa', "Wqa_Station_Details_View")) %>%
  filter(WSD_STATION_ID %in% !! station ) %>% #& #
           #between(as.Date(Fdt_Date_Time), "2014-12-31", "2020-12-31") &
          # !is.na(Fdt_Secchi_Depth)) %>% # x >= left & x <= right
  #dplyr::select(Fdt_Sta_Id, Fdt_Date_Time, Fdt_Depth, Fdt_Secchi_Depth) %>%
  as_tibble()
```




```{r}
#station <- '4AROA167.34'

stationSecchiDepth <- pool %>% tbl(in_schema('wqm', "Wqm_Field_Data_View")) %>%
  filter(Fdt_Sta_Id %in% !! conventionals_distinct$FDT_STA_ID & #station & #
           between(as.Date(Fdt_Date_Time), "2014-12-31", "2020-12-31") &
           !is.na(Fdt_Secchi_Depth)) %>% # x >= left & x <= right
  dplyr::select(Fdt_Sta_Id, Fdt_Date_Time, Fdt_Depth, Fdt_Secchi_Depth) %>%
  as_tibble() %>%
  mutate(Date = as.Date(Fdt_Date_Time)) %>%
    dplyr::select(FDT_STA_ID = Fdt_Sta_Id, Date, FDT_DEPTH = Fdt_Depth, Fdt_Secchi_Depth) # name conventionals format
  #mutate(RMK_SECCHI_DEPTH = as.character(NA), LEVEL_SECCHI_DEPTH = as.factor(NA)) 
```





This is basically the best we can do for now given that 2022 spatial data is still not final as of late March 2021. This is just to get the assessors started, and Cleo has assured that most of this is final final information.

```{r last cycle stations}
lastCycleStation_sf <- st_read('data/GIS/2020_wqms.shp') %>%
  mutate(STATION_ID = toupper(STATION_ID)) # fix messed up stationID names to prevent joining issues
```
